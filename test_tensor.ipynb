{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[-1.0695,  0.6484, -1.2045],\n",
      "        [-0.3317,  1.3867,  1.2335],\n",
      "        [-0.6120,  0.6494,  0.1371]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1차원 텐서 생성 (벡터)\n",
    "tensor_1d = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 2차원 텐서 생성 (행렬)\n",
    "tensor_2d = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 0으로 채워진 3x3 텐서\n",
    "zeros_tensor = torch.zeros(3, 3)\n",
    "\n",
    "# 평균 0, 표준편차 1의 정규분포를 따르는 3x3 텐서\n",
    "randn_tensor = torch.randn(3, 3)\n",
    "\n",
    "print(tensor_1d)\n",
    "print(tensor_2d)\n",
    "print(zeros_tensor)\n",
    "print(randn_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "b = torch.tensor([4, 5, 6])\n",
    "\n",
    "# 텐서 간 덧셈\n",
    "result = a + b\n",
    "# 또는 torch.add(a, b) 사용 가능\n",
    "print(result)  # tensor([5, 7, 9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3, -3, -3])\n"
     ]
    }
   ],
   "source": [
    "result = a - b\n",
    "# 또는 torch.sub(a, b) 사용 가능\n",
    "print(result)  # tensor([-3, -3, -3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4, 10, 18])\n"
     ]
    }
   ],
   "source": [
    "result = a * b\n",
    "# 또는 torch.mul(a, b) 사용 가능\n",
    "print(result)  # tensor([ 4, 10, 18])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 22],\n",
      "        [43, 50]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2], [3, 4]])\n",
    "b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "result = torch.matmul(a, b)\n",
    "# 또는 a @ b\n",
    "print(result)\n",
    "# tensor([[19, 22],\n",
    "#         [43, 50]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([10, 20, 30])\n",
    "b = torch.tensor([2, 4, 5])\n",
    "\n",
    "result = a / b\n",
    "# 또는 torch.div(a, b) 사용 가능\n",
    "print(result)  # tensor([5., 5., 6.])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4,  9, 16])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([2, 3, 4])\n",
    "\n",
    "# 텐서 요소 각각의 제곱\n",
    "result = a ** 2\n",
    "# 또는 torch.pow(a, 2)\n",
    "print(result)  # tensor([ 4,  9, 16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(tensor.shape)  # torch.Size([2, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "reshaped_tensor = tensor.view(3, 2)  # 2x3 텐서를 3x2로 변경\n",
    "print(reshaped_tensor)\n",
    "# tensor([[1, 2],\n",
    "#         [3, 4],\n",
    "#         [5, 6]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21)\n",
      "tensor([5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 전체 합계\n",
    "sum_value = torch.sum(tensor)\n",
    "print(sum_value)  # tensor(21)\n",
    "\n",
    "# 특정 차원의 합계\n",
    "sum_value_dim0 = torch.sum(tensor, dim=0)  # 행을 기준으로 열의 합\n",
    "print(sum_value_dim0)  # tensor([5, 7, 9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5)\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 최댓값\n",
    "max_value = torch.max(tensor)\n",
    "print(max_value)  # tensor(5)\n",
    "\n",
    "# 최솟값\n",
    "min_value = torch.min(tensor)\n",
    "print(min_value)  # tensor(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False,  True,  True])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "\n",
    "# 3보다 큰 값들만 True\n",
    "result = tensor > 3\n",
    "print(result)  # tensor([False, False, False,  True,  True])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([2, 5])\n",
      "tensor(6)\n",
      "tensor([1, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 예시 텐서 생성 (2x3 텐서)\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# 첫 번째 행만 선택\n",
    "slice_1 = tensor[0, :]\n",
    "print(slice_1)  # tensor([1, 2, 3])\n",
    "\n",
    "# 두 번째 열만 선택\n",
    "slice_2 = tensor[:, 1]\n",
    "print(slice_2)  # tensor([2, 5])\n",
    "\n",
    "# 두 번째 행과 세 번째 열의 원소 선택\n",
    "slice_3 = tensor[1, 2]\n",
    "print(slice_3)  # tensor(6)\n",
    "\n",
    "# 특정 영역 (첫 번째 행의 첫 번째와 두 번째 열 선택)\n",
    "slice_4 = tensor[0, 0:2]\n",
    "print(slice_4)  # tensor([1, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n",
      "tensor([[1, 2, 5, 6],\n",
      "        [3, 4, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# 2x2 텐서 두 개 생성\n",
    "tensor_a = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor_b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "# 행 기준(0번 축)으로 붙이기 (2x2 + 2x2 = 4x2)\n",
    "concat_1 = torch.cat((tensor_a, tensor_b), dim=0)\n",
    "print(concat_1)\n",
    "# tensor([[1, 2],\n",
    "#         [3, 4],\n",
    "#         [5, 6],\n",
    "#         [7, 8]])\n",
    "\n",
    "# 열 기준(1번 축)으로 붙이기 (2x2 + 2x2 = 2x4)\n",
    "concat_2 = torch.cat((tensor_a, tensor_b), dim=1)\n",
    "print(concat_2)\n",
    "# tensor([[1, 2, 5, 6],\n",
    "#         [3, 4, 7, 8]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# 1차원 텐서를 2차원으로 변경\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "reshaped_tensor = tensor.view(2, 3)  # 2x3 텐서로 변환\n",
    "print(reshaped_tensor)\n",
    "# tensor([[1, 2, 3],\n",
    "#         [4, 5, 6]])\n",
    "\n",
    "# 다시 1차원으로 변경\n",
    "flattened_tensor = reshaped_tensor.view(-1)  # -1은 나머지 요소를 자동으로 계산\n",
    "print(flattened_tensor)  # tensor([1, 2, 3, 4, 5, 6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([3, 4])\n",
      "tensor([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# 1x6 텐서를 3개의 텐서로 나누기\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "chunks = torch.chunk(tensor, 3)  # 3개의 텐서로 나눔\n",
    "for chunk in chunks:\n",
    "    print(chunk)\n",
    "# tensor([1, 2])\n",
    "# tensor([3, 4])\n",
    "# tensor([5, 6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2])\n",
      "tensor([3, 4])\n",
      "tensor([5, 6])\n"
     ]
    }
   ],
   "source": [
    "# 1x6 텐서를 2개의 원소를 가지는 텐서로 나누기\n",
    "splits = torch.split(tensor, 2)  # 각 텐서가 2개의 원소를 가짐\n",
    "for split in splits:\n",
    "    print(split)\n",
    "# tensor([1, 2])\n",
    "# tensor([3, 4])\n",
    "# tensor([5, 6])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [5, 6]])\n",
      "tensor([[11, 12],\n",
      "        [15, 16]])\n",
      "tensor([[ 1,  2, 11, 12],\n",
      "        [ 5,  6, 15, 16]])\n"
     ]
    }
   ],
   "source": [
    "# 예시 텐서 생성 (4x4 텐서)\n",
    "tensor = torch.tensor([\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8],\n",
    "    [9, 10, 11, 12],\n",
    "    [13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "# 2x2 텐서로 자르기\n",
    "top_left = tensor[:2, :2]   # 왼쪽 상단\n",
    "bottom_right = tensor[2:, 2:]  # 오른쪽 하단\n",
    "\n",
    "# 자른 텐서 출력\n",
    "print(top_left)\n",
    "# tensor([[1, 2],\n",
    "#         [5, 6]])\n",
    "\n",
    "print(bottom_right)\n",
    "# tensor([[11, 12],\n",
    "#         [15, 16]])\n",
    "\n",
    "# 자른 텐서를 다시 붙이기\n",
    "new_tensor = torch.cat((top_left, bottom_right), dim=1)\n",
    "print(new_tensor)\n",
    "# tensor([[ 1,  2, 11, 12],\n",
    "#         [ 5,  6, 15, 16]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1, 2], [3, 4]])\n",
    "# 데이터를 입력으로 받아서 텐서를 생성\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "zeros_tensor = torch.zeros(3, 3)\n",
    "# 모든 요소가 0인 텐서를 생성\n",
    "print(zeros_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "ones_tensor = torch.ones(2, 4)\n",
    "# 모든 요소가 1인 텐서를 생성\n",
    "print(ones_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_tensor = torch.rand(3, 3)\n",
    "# 0과 1 사이의 균등 분포를 따르는 난수로 이루어진 텐서를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "randn_tensor = torch.randn(3, 3)\n",
    "# 평균이 0이고 표준 편차가 1인 정규 분포를 따르는 난수로 이루어진 텐서를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "linspace_tensor = torch.linspace(0, 1, 5)  # tensor([0.0000, 0.2500, 0.5000, 0.7500, 1.0000])\n",
    "# 주어진 범위 내에서 일정 간격으로 나뉜 값을 가지는 1차원 텐서를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eye_tensor = torch.eye(3)  # 3x3 단위 행렬 생성\n",
    "# 단위 행렬을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "reshaped_tensor = tensor.reshape(3, 2)  # tensor([[1, 2], [3, 4], [5, 6]])\n",
    "# 텐서의 모양을 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "transposed_tensor = tensor.transpose(0, 1)  # tensor([[1, 4], [2, 5], [3, 6]])\n",
    "# 주어진 두 차원을 교환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "flattened_tensor = tensor.flatten()  # tensor([1, 2, 3, 4, 5, 6])\n",
    "# 여러 차원의 텐서를 1차원으로 평탄화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[[1, 2, 3]]])  # shape: (1, 1, 3)\n",
    "squeezed_tensor = torch.squeeze(tensor)  # tensor([1, 2, 3]) - shape: (3,)\n",
    "# 차원이 1인 차원을 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3])  # shape: (3,)\n",
    "unsqueezed_tensor = torch.unsqueeze(tensor, 0)  # tensor([[1, 2, 3]]) - shape: (1, 3)\n",
    "# 지정한 차원에 크기가 1인 차원을 추가\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "tensor_a = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor_b = torch.tensor([[5, 6], [7, 8]])\n",
    "concatenated_tensor = torch.cat((tensor_a, tensor_b), dim=0)  \n",
    "# tensor([[1, 2], [3, 4], [5, 6], [7, 8]])\n",
    "# 주어진 차원을 기준으로 여러 텐서를 이어 붙이기\n",
    "print(concatenated_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_a = torch.tensor([1, 2])\n",
    "tensor_b = torch.tensor([3, 4])\n",
    "stacked_tensor = torch.stack((tensor_a, tensor_b), dim=0)  # tensor([[1, 2], [3, 4]])\n",
    "# 주어진 차원을 따라 여러 텐서를 쌓아 올리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3, 4, 5, 6])\n",
    "split_tensors = torch.split(tensor, 2)  # 각 텐서의 크기가 2인 부분으로 나눔\n",
    "for t in split_tensors:\n",
    "    print(t)\n",
    "# tensor([1, 2])\n",
    "# tensor([3, 4])\n",
    "# tensor([5, 6])\n",
    "# 텐서를 일정한 크기로 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(tensor.size())  # torch.Size([2, 3])\n",
    "# 텐서의 크기 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(tensor.numel())  # 6\n",
    "# 텐서의 총 원소 개수를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(tensor.dim())  # 2\n",
    "# 텐서의 차원 수를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "sum_all = torch.sum(tensor)  # 21\n",
    "sum_dim0 = torch.sum(tensor, dim=0)  # tensor([5, 7, 9])\n",
    "sum_dim1 = torch.sum(tensor, dim=1)  # tensor([6, 15])\n",
    "# 지정한 차원의 합을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "mean_all = torch.mean(tensor.float())  # 3.5\n",
    "mean_dim0 = torch.mean(tensor.float(), dim=0)  # tensor([2.5, 3.5, 4.5])\n",
    "# 지정한 차원의 평균을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "max_value = torch.max(tensor)  # 6\n",
    "# 지정한 차원에서 최솟값을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "max_index = torch.argmax(tensor)  # 5 (1차원 인덱스)\n",
    "max_index_dim1 = torch.argmax(tensor, dim=1)  # tensor([2, 2]) (각 행에서 최대값의 인덱스)\n",
    "# 지정된 차원에서 최대값의 인덱스를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "min_index = torch.argmin(tensor)  # 0 (1차원 인덱스)\n",
    "min_index_dim1 = torch.argmin(tensor, dim=1)  # tensor([0, 0]) (각 행에서 최솟값의 인덱스)\n",
    "# 지정된 차원에서 최솟값의 인덱스를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([3, 1, 2, 5, 4])\n",
    "sorted_tensor, sorted_indices = torch.sort(tensor)\n",
    "print(sorted_tensor)  # tensor([1, 2, 3, 4, 5])\n",
    "print(sorted_indices)  # tensor([1, 2, 0, 4, 3])\n",
    "# 텐서를 정렬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 3, 2, 5, 4])\n",
    "top_values, top_indices = torch.topk(tensor, k=3)\n",
    "print(top_values)  # tensor([5, 4, 3])\n",
    "print(top_indices)  # tensor([3, 4, 1])\n",
    "# 가장 큰 값 k개를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([0.5, 2.0, 3.5, 5.0, 7.0])\n",
    "clamped_tensor = torch.clamp(tensor, min=1.0, max=5.0)\n",
    "print(clamped_tensor)  # tensor([1.0, 2.0, 3.5, 5.0, 5.0])\n",
    "# 텐서의 값을 지정한 범위로 제한"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "condition = tensor > 3\n",
    "result = torch.where(condition, tensor, torch.tensor(0))\n",
    "print(result)  # tensor([0, 0, 0, 4, 5])\n",
    "# 조건에 따라 요소를 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([[0, 1, 0], [2, 0, 3]])\n",
    "non_zero_indices = torch.nonzero(tensor)\n",
    "print(non_zero_indices)\n",
    "# tensor([[0, 1],\n",
    "#         [1, 0],\n",
    "#         [1, 2]])\n",
    "# 0이 아닌 요소의 인덱스를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([0, 1, 2, 3])\n",
    "print(torch.any(tensor))  # True (0이 아닌 요소가 있음)\n",
    "print(torch.all(tensor))  # False (0이 있음)\n",
    "# torch.any(): 텐서의 요소 중 하나라도 참이면 True를 반환\n",
    "# torch.all(): 텐서의 모든 요소가 참이면 True를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3, 4])\n",
    "cumsum_tensor = torch.cumsum(tensor, dim=0)\n",
    "print(cumsum_tensor)  # tensor([ 1,  3,  6, 10])\n",
    "\n",
    "cumprod_tensor = torch.cumprod(tensor, dim=0)\n",
    "print(cumprod_tensor)  # tensor([ 1,  2,  6, 24])\n",
    "\n",
    "# torch.cumsum(): 누적 합을 계산\n",
    "# torch.cumprod(): 누적 곱을 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 A:\n",
      "[[1 2 3]\n",
      " [4 5 6]]\n",
      "\n",
      "행렬 B:\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]]\n",
      "\n",
      "행렬 A와 B의 곱 C:\n",
      "[[ 58  64]\n",
      " [139 154]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 행렬 A 정의 (2x3 행렬)\n",
    "A = np.array([[1, 2, 3],\n",
    "            [4, 5, 6]])\n",
    "\n",
    "# 행렬 B 정의 (3x2 행렬)\n",
    "B = np.array([[7, 8],\n",
    "            [9, 10],\n",
    "            [11, 12]])\n",
    "\n",
    "# 행렬 곱셈 수행 (A @ B 또는 np.dot(A, B) 사용 가능)\n",
    "C = np.matmul(A, B)\n",
    "# 또는 C = np.dot(A, B)\n",
    "# 또는 C = A @ B\n",
    "\n",
    "print(\"행렬 A:\")\n",
    "print(A)\n",
    "print(\"\\n행렬 B:\")\n",
    "print(B)\n",
    "print(\"\\n행렬 A와 B의 곱 C:\")\n",
    "print(C)\n",
    "\n",
    "# NumPy를 이용한 행렬 곱셈 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 A:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "\n",
      "행렬 B:\n",
      "tensor([[ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "\n",
      "행렬 A와 B의 곱 C:\n",
      "tensor([[ 58,  64],\n",
      "        [139, 154]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 행렬 A 정의 (2x3 텐서)\n",
    "A = torch.tensor([[1, 2, 3],\n",
    "                [4, 5, 6]])\n",
    "\n",
    "# 행렬 B 정의 (3x2 텐서)\n",
    "B = torch.tensor([[7, 8],\n",
    "                [9, 10],\n",
    "                [11, 12]])\n",
    "\n",
    "# 행렬 곱셈 수행\n",
    "C = torch.matmul(A, B)\n",
    "# 또는 C = A @ B\n",
    "\n",
    "print(\"행렬 A:\")\n",
    "print(A)\n",
    "print(\"\\n행렬 B:\")\n",
    "print(B)\n",
    "print(\"\\n행렬 A와 B의 곱 C:\")\n",
    "print(C)\n",
    "\n",
    "# PyTorch를 이용한 행렬 곱셈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요소별 곱셈 결과:\n",
      "[[ 5 12]\n",
      " [21 32]]\n"
     ]
    }
   ],
   "source": [
    "# 요소별 곱셈 (Element-wise Multiplication)\n",
    "# 요소별 곱셈은 동일한 위치의 요소들끼리 곱하는 연산으로, Hadamard 곱\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 동일한 크기의 행렬 정의\n",
    "A = np.array([[1, 2],\n",
    "            [3, 4]])\n",
    "\n",
    "B = np.array([[5, 6],\n",
    "            [7, 8]])\n",
    "\n",
    "# 요소별 곱셈\n",
    "C_elementwise = A * B\n",
    "\n",
    "print(\"요소별 곱셈 결과:\")\n",
    "print(C_elementwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "행렬 곱셈 결과:\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "# 행렬 곱셈 (Matrix Multiplication)\n",
    "# 위의 행렬 A와 B에 대해 행렬 곱셈을 수행하면:\n",
    "# 행렬 곱셈\n",
    "C_matrix = np.matmul(A, B)\n",
    "# 또는 C_matrix = A @ B\n",
    "\n",
    "print(\"\\n행렬 곱셈 결과:\")\n",
    "print(C_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "차이점!\n",
    "# 요소별 곱셈은 각 위치의 요소를 단순히 곱하는 것이며, 결과 행렬의 크기는 원본 행렬과 동일합니다.\n",
    "# 행렬 곱셈은 선형 대수의 규칙에 따라 계산되며, 결과 행렬의 크기는 (A의 행 수 x B의 열 수)입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "행렬 A:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "\n",
      "행렬 B:\n",
      "[[5 6]\n",
      " [7 8]]\n",
      "\n",
      "요소별 곱셈 결과:\n",
      "[[ 5 12]\n",
      " [21 32]]\n",
      "\n",
      "행렬 곱셈 결과:\n",
      "[[19 22]\n",
      " [43 50]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 행렬 A 정의\n",
    "A = np.array([[1, 2],\n",
    "            [3, 4]])\n",
    "\n",
    "# 행렬 B 정의\n",
    "B = np.array([[5, 6],\n",
    "            [7, 8]])\n",
    "\n",
    "# 요소별 곱셈\n",
    "C_elementwise = A * B\n",
    "\n",
    "# 행렬 곱셈\n",
    "C_matrix = np.matmul(A, B)\n",
    "# 또는 C_matrix = A @ B\n",
    "\n",
    "print(\"행렬 A:\")\n",
    "print(A)\n",
    "print(\"\\n행렬 B:\")\n",
    "print(B)\n",
    "print(\"\\n요소별 곱셈 결과:\")\n",
    "print(C_elementwise)\n",
    "print(\"\\n행렬 곱셈 결과:\")\n",
    "print(C_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요약 및 정리\n",
    "행렬 곱셈은 선형 변환을 적용하는 연산으로, 머신러닝 모델에서 입력 데이터에 가중치를 적용할 때 사용됩니다.\n",
    "요소별 곱셈은 동일한 위치의 요소를 곱하는 연산으로, 신경망에서 주로 활성화 맵을 조정하거나 마스크를 적용할 때 사용됩니다.\n",
    "Python의 NumPy와 PyTorch는 모두 행렬 연산을 효율적으로 수행할 수 있는 함수와 메소드를 제공합니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aebon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
