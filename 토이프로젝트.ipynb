{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\cifar-10-python.tar.gz to ./data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 1, Loss: 1.2806533791854149\n",
      "Epoch 2, Loss: 0.8887319237241665\n",
      "Epoch 3, Loss: 0.6971527811471118\n",
      "Epoch 4, Loss: 0.5296784670915042\n",
      "Epoch 5, Loss: 0.37058740129702683\n",
      "Epoch 6, Loss: 0.2421346521618766\n",
      "Epoch 7, Loss: 0.1536829249804657\n",
      "Epoch 8, Loss: 0.11462043292262733\n",
      "Epoch 9, Loss: 0.10082796327555248\n",
      "Epoch 10, Loss: 0.08420125113711385\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# 모델 초기화\n",
    "model = CNN()\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss()  # 분류 문제이므로 CrossEntropyLoss 사용\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam 옵티마이저\n",
    "\n",
    "# 학습 루프\n",
    "num_epochs = 10  # 학습 반복 횟수\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        # 옵티마이저 초기화\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 순전파 (Forward pass)\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # 손실 계산\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # 역전파 (Backward pass) 및 최적화\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실 누적\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # 에포크마다 평균 손실 출력\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# 모델 저장 (옵션)\n",
    "torch.save(model.state_dict(), 'cnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Epoch 1, Loss: 1.2508139729271008\n",
      "Epoch 2, Loss: 0.858227761697098\n",
      "Epoch 3, Loss: 0.6571506361929331\n",
      "Epoch 4, Loss: 0.47599641548771165\n",
      "Epoch 5, Loss: 0.307143199032915\n",
      "Epoch 6, Loss: 0.1857088731008362\n",
      "Epoch 7, Loss: 0.13086319744398653\n",
      "Epoch 8, Loss: 0.1021900220407067\n",
      "Epoch 9, Loss: 0.08317620774529343\n",
      "Epoch 10, Loss: 0.07451604821990195\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 이미지 데이터를 텐서로 변환하고 정규화하는 변환 정의\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# CIFAR-10 데이터셋을 불러와서 학습용으로 사용, 다운로드 여부 확인 후 변환 적용\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# 데이터셋을 DataLoader로 변환하여 배치 단위로 학습할 수 있도록 함\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "\n",
    "# CNN 모델 클래스 정의\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 첫 번째 합성곱 레이어 정의: 입력 채널 3, 출력 채널 32, 커널 크기 3x3, 패딩 1\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        # 두 번째 합성곱 레이어 정의: 입력 채널 32, 출력 채널 64, 커널 크기 3x3, 패딩 1\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # 첫 번째 전결합 레이어 정의: 입력 뉴런 수 64 * 8 * 8 (합성곱 결과의 펼친 크기), 출력 뉴런 512\n",
    "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
    "        # 두 번째 전결합 레이어 정의: 입력 뉴런 512, 출력 뉴런 10 (CIFAR-10 클래스 수)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    # 순전파 함수 정의\n",
    "    def forward(self, x):\n",
    "        # 첫 번째 합성곱 -> ReLU 활성화 함수 적용\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        # Max pooling (2x2) 적용하여 차원 축소\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        # 두 번째 합성곱 -> ReLU 활성화 함수 적용\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        # Max pooling (2x2) 적용하여 차원 축소\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        # 차원 축소된 데이터를 1차원으로 펼치기 (batch size 제외)\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        # 첫 번째 전결합 레이어 -> ReLU 활성화 함수 적용\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        # 두 번째 전결합 레이어 (최종 출력)\n",
    "        return self.fc2(x)\n",
    "\n",
    "# CNN 모델 객체 생성\n",
    "model = CNN()\n",
    "\n",
    "# 손실 함수 정의: Cross Entropy Loss (다중 클래스 분류에 적합)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Adam 옵티마이저 정의: 모델의 파라미터와 학습률 설정\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 학습 에포크 수 설정\n",
    "num_epochs = 10\n",
    "\n",
    "# 학습 루프\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0  # 현재 에포크의 손실을 누적할 변수 초기화\n",
    "    for inputs, labels in trainloader:  # 배치 단위로 데이터를 불러옴\n",
    "        optimizer.zero_grad()  # 옵티마이저의 이전 배치에서 계산된 그래디언트 초기화\n",
    "\n",
    "        outputs = model(inputs)  # 입력 데이터를 모델에 통과시켜 출력 계산 (순전파)\n",
    "        \n",
    "        loss = criterion(outputs, labels)  # 출력값과 정답(label) 간의 손실 계산\n",
    "\n",
    "        loss.backward()  # 손실을 기반으로 역전파 수행하여 그래디언트 계산\n",
    "\n",
    "        optimizer.step()  # 옵티마이저가 계산된 그래디언트를 사용하여 가중치 업데이트\n",
    "\n",
    "        running_loss += loss.item()  # 배치의 손실 값을 누적\n",
    "\n",
    "    # 에포크 완료 후 평균 손실 출력\n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss / len(trainloader)}\")\n",
    "\n",
    "# 학습 완료 메시지 출력\n",
    "print('Finished Training')\n",
    "\n",
    "# 학습된 모델의 파라미터 저장\n",
    "torch.save(model.state_dict(), 'cnn_model.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주석 설명\n",
    "\n",
    "데이터셋 로드 및 전처리:\n",
    "\n",
    "transforms.Compose를 통해 이미지를 텐서로 변환하고 정규화(평균 0.5, 표준편차 0.5)를 적용합니다.\n",
    "trainloader는 배치 크기 32로 CIFAR-10 데이터를 로드하고, 학습에 사용할 수 있도록 제공합니다.\n",
    "\n",
    "모델 정의:\n",
    "두 개의 합성곱 레이어와 두 개의 전결합 레이어로 구성된 CNN 모델입니다.\n",
    "각 합성곱 레이어 이후에 ReLU 활성화 함수와 MaxPooling을 사용하여 차원을 축소하고 비선형성을 추가합니다.\n",
    "마지막에 펼친 벡터 형태의 출력을 전결합 레이어로 전달하여 CIFAR-10의 10개 클래스에 대해 예측합니다.\n",
    "\n",
    "학습 루프:\n",
    "손실 함수는 Cross Entropy Loss로, 다중 클래스 분류에서 자주 사용되는 손실 함수입니다.\n",
    "Adam 옵티마이저를 사용해 모델의 가중치를 업데이트합니다.\n",
    "매 에포크가 끝날 때마다 평균 손실 값을 출력하여 학습 진행 상황을 확인합니다.\n",
    "\n",
    "모델 저장:\n",
    "학습이 완료되면 model.state_dict()를 사용하여 모델의 파라미터를 저장합니다. 이 파일을 나중에 로드하여 모델을 재사용할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mjjenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "94869f568b959b665414287b7e71fc2e2483d76b817f8a1b19ffae13ace580cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
